# Workflow Comparison: Standard vs Diff-Based Testing

Visual comparison of the two testing modes available in MonkeyTest.

## Quick Comparison Table

| Feature | Standard Mode | Diff-Based Mode |
|---------|--------------|-----------------|
| **Test Source** | Pre-written markdown files | Auto-generated from git diff |
| **Setup Complexity** | Low (just write tests) | Medium (needs OpenAI API) |
| **API Keys Required** | Browser Use only | Browser Use + OpenAI |
| **Use Case** | Manual test scenarios | PR/commit testing |
| **Cost** | Browser Use execution only | OpenAI generation + Browser Use execution |
| **Speed** | Fast (no generation) | Slower (generation + execution) |
| **Test Quality** | Human-curated | AI-generated (variable) |
| **Maintenance** | Manual updates needed | Automatic for code changes |

## Mode 1: Standard Mode (v0.5 Compatible)

### Use Case
Run pre-written test cases from your repository.

### Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Standard Mode Flow                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Developer writes tests manually
    â”‚
    â”œâ”€ Create tests/login.md
    â”œâ”€ Create tests/checkout.md
    â””â”€ Create tests/search.md
    â”‚
    v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Push to Repository      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Actions Trigger  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Checkout Repository     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Run MonkeyTest Action   â”‚
â”‚  with test-directory     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser Use reads       â”‚
â”‚  markdown test files     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Execute tests           â”‚
â”‚  (Browser automation)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Collect results         â”‚
â”‚  Generate report         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
    Upload Artifacts
    Show Summary
    âœ… Done!
```

### Example Workflow

```yaml
name: Standard Tests

on:
  push:
    branches: [main]
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Tests
        uses: aevsai/monkey-test@v0.6
        with:
          api-key: ${{ secrets.BROWSER_USE_API_KEY }}
          test-directory: tests

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: test-results.json
```

### Pros âœ…
- Simple setup
- Predictable tests
- Human-curated quality
- Fast execution
- Lower cost (no LLM generation)
- Full control over test scenarios

### Cons âŒ
- Manual test writing required
- Tests can become outdated
- Doesn't scale with rapid development
- Requires test maintenance

---

## Mode 2: Diff-Based Mode (v0.6 New Feature)

### Use Case
Automatically generate tests from code changes in PRs or commits.

### Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Diff-Based Mode Flow                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Developer makes code changes
    â”‚
    â”œâ”€ Modify src/login.tsx
    â”œâ”€ Update api/checkout.ts
    â””â”€ Change components/search.tsx
    â”‚
    v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Create PR / Push        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Actions Trigger  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Checkout with History   â”‚
â”‚  (fetch-depth: 0)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extract Git Diff        â”‚
â”‚  (compare commits)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Send Diff to GPT-4      â”‚
â”‚  with prompt             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM analyzes changes    â”‚
â”‚  Generates test cases    â”‚
â”‚  Returns XML             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parse XML response      â”‚
â”‚  Convert to markdown     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Save generated tests    â”‚
â”‚  to temp directory       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Execute generated tests â”‚
â”‚  (Browser Use)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Collect results         â”‚
â”‚  Save artifacts          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             v
    Upload Artifacts
    - Generated tests
    - Diff
    - LLM response
    - Test results
    Comment on PR
    âœ… Done!
```

### Example Workflow

```yaml
name: Auto-Generated Tests

on:
  pull_request:
    branches: [main]

jobs:
  auto-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Generate and Run Tests
        uses: aevsai/monkey-test@v0.6
        with:
          from-commit: ${{ github.event.pull_request.base.sha }}
          openai-api-key: ${{ secrets.OPENAI_API_KEY }}
          api-key: ${{ secrets.BROWSER_USE_API_KEY }}
          max-test-cases: 10

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: auto-test-results
          path: |
            .monkey-test-generated/
            artifacts/
            test-results.json
```

### Pros âœ…
- Zero manual test writing
- Tests always match code changes
- Scales automatically with development
- Fresh perspective from AI
- Documents what changed
- Catches edge cases you might miss

### Cons âŒ
- Requires OpenAI API key
- Higher cost (LLM + execution)
- Slower (generation step)
- AI-generated quality varies
- May generate irrelevant tests
- Requires review of generated tests

---

## Hybrid Approach (Recommended)

Combine both modes for comprehensive coverage!

### Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Hybrid Testing Flow                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Pull Request Created
            â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                     â”‚
            v                     v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Job 1:       â”‚     â”‚  Job 2:      â”‚
    â”‚  Manual Tests â”‚     â”‚  Auto Tests  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                     â”‚
            â”‚                     â”‚
    Run existing tests    Generate from diff
    from tests/           Execute generated
            â”‚                     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      v
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Job 3:       â”‚
              â”‚  Combine      â”‚
              â”‚  Report       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      v
              Comprehensive
              Test Coverage!
```

### Example Hybrid Workflow

```yaml
name: Comprehensive Testing

on:
  pull_request:
    branches: [main]

jobs:
  # Critical manual tests (always run)
  manual-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Manual Tests
        uses: aevsai/monkey-test@v0.6
        with:
          api-key: ${{ secrets.BROWSER_USE_API_KEY }}
          test-directory: tests/critical

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: manual-results
          path: test-results.json

  # Auto-generated tests (from changes)
  auto-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Generate and Run Tests
        uses: aevsai/monkey-test@v0.6
        with:
          from-commit: ${{ github.event.pull_request.base.sha }}
          openai-api-key: ${{ secrets.OPENAI_API_KEY }}
          api-key: ${{ secrets.BROWSER_USE_API_KEY }}
          max-test-cases: 5

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: auto-results
          path: |
            .monkey-test-generated/
            test-results.json

  # Combined report
  report:
    needs: [manual-tests, auto-tests]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - uses: actions/download-artifact@v4

      - name: Create Report
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let comment = '## ğŸ§ª Test Results\n\n';
            
            // Manual tests
            if (fs.existsSync('manual-results/test-results.json')) {
              const manual = JSON.parse(fs.readFileSync('manual-results/test-results.json'));
              comment += `### Manual Tests\n`;
              comment += `- Total: ${manual.summary.total}\n`;
              comment += `- Passed: ${manual.summary.passed}\n`;
              comment += `- Failed: ${manual.summary.failed}\n\n`;
            }
            
            // Auto tests
            if (fs.existsSync('auto-results/test-results.json')) {
              const auto = JSON.parse(fs.readFileSync('auto-results/test-results.json'));
              comment += `### Auto-Generated Tests\n`;
              comment += `- Total: ${auto.summary.total}\n`;
              comment += `- Passed: ${auto.summary.passed}\n`;
              comment += `- Failed: ${auto.summary.failed}\n\n`;
            }
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
```

---

## Cost Comparison

### Standard Mode
```
Cost per PR = Browser Use execution cost only

Example:
- 10 tests
- ~30 seconds each
- Browser Use: $X per minute
= 10 Ã— 0.5 min Ã— $X = 5X cost
```

### Diff-Based Mode
```
Cost per PR = OpenAI generation + Browser Use execution

Example:
- Generate 5 tests (GPT-4 Turbo)
  - Input: ~3K tokens Ã— $0.01/1K = $0.03
  - Output: ~2K tokens Ã— $0.03/1K = $0.06
  - Generation cost: ~$0.09
- Execute 5 tests
  - 5 Ã— 0.5 min Ã— $X = 2.5X cost
= $0.09 + 2.5X total cost
```

### Hybrid Mode
```
Cost per PR = Standard + Diff-Based

Example:
- 5 critical manual tests = 2.5X
- 5 auto-generated tests = $0.09 + 2.5X
= $0.09 + 5X total cost
```

### Cost Optimization Tips

1. **Use `generate-only` for preview** (no execution cost)
2. **Use GPT-3.5 for simple changes** (~90% cheaper generation)
3. **Limit `max-test-cases`** (fewer tests = lower cost)
4. **Use conditional execution** (only on certain file changes)
5. **Require approval for full runs** (use GitHub environments)

---

## When to Use Which Mode

### Use Standard Mode When:
- âœ… You have well-defined test scenarios
- âœ… Tests are stable and rarely change
- âœ… You want full control over test quality
- âœ… Cost is a primary concern
- âœ… Speed is critical
- âœ… Testing production-critical flows

### Use Diff-Based Mode When:
- âœ… Rapid development with frequent changes
- âœ… PR review process benefits from auto-tests
- âœ… You want to catch regressions automatically
- âœ… Documentation of changes is valuable
- âœ… Team is comfortable reviewing AI-generated tests
- âœ… Testing new features before manual tests exist

### Use Hybrid Mode When:
- âœ… You want best of both worlds
- âœ… Critical paths need manual tests
- âœ… New changes need automatic coverage
- âœ… Maximum test coverage is goal
- âœ… Budget allows for both approaches

---

## Migration Path

### Step 1: Start with Standard Mode (v0.5)
```yaml
- uses: aevsai/monkey-test@v0.5
  with:
    api-key: ${{ secrets.BROWSER_USE_API_KEY }}
    test-directory: tests
```

### Step 2: Add Diff-Based Preview (v0.6)
```yaml
# Keep existing tests
- uses: aevsai/monkey-test@v0.6
  with:
    api-key: ${{ secrets.BROWSER_USE_API_KEY }}
    test-directory: tests

# Add preview job
- uses: aevsai/monkey-test@v0.6
  with:
    from-commit: main
    openai-api-key: ${{ secrets.OPENAI_API_KEY }}
    generate-only: true
```

### Step 3: Enable Full Auto-Testing (v0.6)
```yaml
# Manual tests
- uses: aevsai/monkey-test@v0.6
  with:
    api-key: ${{ secrets.BROWSER_USE_API_KEY }}
    test-directory: tests

# Auto tests
- uses: aevsai/monkey-test@v0.6
  with:
    from-commit: main
    openai-api-key: ${{ secrets.OPENAI_API_KEY }}
    api-key: ${{ secrets.BROWSER_USE_API_KEY }}
```

---

## Summary

| Aspect | Standard | Diff-Based | Hybrid |
|--------|----------|------------|--------|
| **Setup Effort** | High | Low | Medium |
| **Runtime Cost** | Low | Medium | High |
| **Test Quality** | High | Variable | High |
| **Maintenance** | High | Low | Medium |
| **Coverage** | Manual | Automatic | Both |
| **Best For** | Stable apps | Rapid dev | Production |

**Recommendation**: Start with Standard mode, add Diff-Based previews, then upgrade to Hybrid for production.

---

**Version**: 1.0.0  
**Last Updated**: January 2024